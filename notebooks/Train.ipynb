{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beefc598-b578-4420-ae2a-14ba2ea15a9e",
   "metadata": {},
   "source": [
    "# Train example notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe940bf-d307-4329-a62d-5b3810a293b9",
   "metadata": {},
   "source": [
    "This notebook is used to implement the training of a neural network for classification of `Cloud`, `Edge`, `Good` images. <br> It is advisable to use this notebook to get practice and debug your code. To speed up the execution, once you are ready, you should move to a scripted version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c79b286-de2e-4f79-b04f-f5dc77e50c59",
   "metadata": {},
   "source": [
    "## 1. - Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5a0112-75c6-4fd4-887d-0c1fe660c9ac",
   "metadata": {},
   "source": [
    "Select `CUDA_VISIBLE_DEVICES` to the `Graphics Proceesing Unit (GPU)` index that you want to use to enable the use of GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b7db3603-a5ec-4fd2-ae28-4571762fc480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "True\n",
      "Available GPUs: 1\n",
      "GPU 0: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import torch\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # GPU index\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Check available GPUs\n",
    "print(\"Available GPUs:\", torch.cuda.device_count())\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62227b7f-8c1a-479f-ae34-84611d656702",
   "metadata": {},
   "source": [
    "Enabling autoreload of different packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a09a54f6-3fc4-463a-a93f-72cdd4ea75d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "26166ece-1cb3-4231-b2c6-3df9b39488c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import sys\n",
    "sys.path.insert(1, os.path.join(\"..\", \"data\"))\n",
    "sys.path.insert(1, os.path.join(\"..\", \"utils\"))\n",
    "from data_utils import Dataset\n",
    "from plot_utils import plot_image\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e285782-59e0-4816-bcf8-bf66981200a2",
   "metadata": {},
   "source": [
    "## 2. - Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef7a7a3-d603-4050-9fb4-f1a20c09a072",
   "metadata": {},
   "source": [
    "### 2.1 - Creating datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462d110f-1b25-4445-bd84-1a29f9261e7e",
   "metadata": {},
   "source": [
    "Now we read the images from the target directory `path_data`. Set `path_data` to the directory containing the `Cloud`, `Edge`, `Good` subfolders.  Moreover, it will automatically split the total dataset into the train, cross validation and test splits by using a pseudo-random splitting algorithm. You can reproduce the split by specifying the variable `seed`. **NB**:\n",
    "- The train split contains 70% of the whole images.\n",
    "- The valid splits contains 15% of the whole images.\n",
    "- The test splits contains 15% of the whole images.\n",
    "<br>**YOU MUST NOT CHANGE THE TEST SPLIT SIZE!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "84b8b832-ce8e-4512-9bdb-6c73d715feb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the data folder (update the variable to your path).\n",
    "path_data=os.path.join(\"..\", \"data\")\n",
    "# Seed value\n",
    "seed=15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2866840-8962-4d55-8461-5819cc496008",
   "metadata": {},
   "source": [
    "<img src=\"utilities/images/danger_icon.png\" style=\"margin:auto\"/>\n",
    "\n",
    "**N.B** Make sure to have created a dataset split into the three directories `Cloud`, and `Good`, `Edge`. Otherwise, the next cell will **fail!** <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d16b581c-5f04-4315-b14a-44bad116a22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing class: Cloud: 141it [00:07, 18.98it/s]\n",
      "Parsing class: Edge: 97it [00:04, 21.50it/s]\n",
      "Parsing class: Good: 66it [00:03, 18.66it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset=Dataset(path_data=path_data, seed=seed)\n",
    "dataset.read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c19bcb-6b39-4258-9d5b-157dab7bc253",
   "metadata": {},
   "source": [
    "**Hint:** before proceeding, make sure that your `Edge`,`Cloud`, and `Good` samples are well enough among the `train`, `valid`,`test` splits. To print datasets statistics, run the next line.  Remember that the number of images in the different splits is distributed as described above. <br> If you are not happy with the data distribution, you can update the seed used and create a new dataset by rerunning the cell above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "57b0127d-d729-48e7-a1c4-557606850ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cloud</th>\n",
       "      <td>97</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edge</th>\n",
       "      <td>70</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train  valid  test\n",
       "cloud     97     22    22\n",
       "edge      70     15    12\n",
       "good      45      9    12"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200c1e33-6c9d-4020-bb4b-9a95cd7e77fa",
   "metadata": {},
   "source": [
    "### 2.2. - Create data loaders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5d1f4c-2378-4ec9-87da-0f4fd2f4086f",
   "metadata": {},
   "source": [
    "The next lines will create a dataloader. A data loader is used to break the dataset into batches of a size `batch_size`. <br> This is useful to ensure that your dataset will fit into your memory and to create a \"stochastic\" implementation of gradient descent. <br> For more information, please, check: [data loader](https://www.educative.io/answers/what-is-pytorch-dataloader).<br>\n",
    "Specify `batch_size` (**Hint**: use powers of 2. Typical values are between 8 and 64)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "209d3834-94e0-4965-9a3e-3525211af1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5e0f8a6d-d620-424d-abae-48789e9c64f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loader\n",
    "train_loader = DataLoader(dataset.get_split(\"train\"), batch_size=batch_size, pin_memory=False, shuffle=True)\n",
    "# Cross validation data loader\n",
    "valid_loader = DataLoader(dataset.get_split(\"valid\"), batch_size=46, pin_memory=False, shuffle=True)\n",
    "# Test data loader\n",
    "test_loader = DataLoader(dataset.get_split(\"test\"), batch_size=batch_size, pin_memory=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdec454c-0b6d-411c-bc63-7223de91dabd",
   "metadata": {},
   "source": [
    "## 3 - Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772b7c14-2bf3-47c7-a2ff-ab80c5aa2c0a",
   "metadata": {},
   "source": [
    "Now, it is your turn! Add your code below to load a Neural Network model, select optimizers, learning rate and perform training. <br>\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "abefe169",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('cloud', 'edge', 'good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "32be015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid \n",
    "import torch.nn.functional as F \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def resize_tensor_images(images, size=(256, 256)):\n",
    "    # Resize the batch of images\n",
    "    return F.interpolate(images, size=size, mode='bilinear', align_corners=False)\n",
    "\n",
    "\n",
    "def compute_mean_std(loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_images_count = 0\n",
    "\n",
    "    for images, _ in loader:\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "        total_images_count += batch_samples\n",
    "\n",
    "    mean /= total_images_count\n",
    "    std /= total_images_count\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "def normalize_images(images, mean, std):\n",
    "    normalized_images = (images - mean.view(-1, 1, 1)) / std.view(-1, 1, 1)\n",
    "    return normalized_images\n",
    "    \n",
    "def tensor_to_numpy(tensor):\n",
    "    # Rescale the tensor to 0-1 range\n",
    "    tensor = tensor - tensor.min()\n",
    "    tensor = tensor / tensor.max()\n",
    "    # Move the tensor to CPU if it's on GPU\n",
    "    tensor = tensor.cpu()\n",
    "\n",
    "    # Convert to numpy and transpose from CxHxW to HxWxC for visualization\n",
    "    numpy_image = tensor.numpy()\n",
    "    numpy_image = np.transpose(numpy_image, (1, 2, 0))\n",
    "\n",
    "    return numpy_image\n",
    "\n",
    "def normalize_individual_image(image):\n",
    "    # Calculate the mean and std for each channel of the image\n",
    "    mean = image.mean(dim=[1, 2])\n",
    "    std = image.std(dim=[1, 2])\n",
    "\n",
    "    # Ensure std is not zero to avoid division by zero\n",
    "    std = std.clamp(min=1e-9)\n",
    "\n",
    "    # Normalize the image\n",
    "    normalized_image = (image - mean[:, None, None]) / std[:, None, None]\n",
    "    return normalized_image\n",
    "\n",
    "normalized_batches_TRL = []\n",
    "normalized_batches_VAL = []\n",
    "normalized_batches_test = []\n",
    "for batch in train_loader:\n",
    "    images, labels = batch\n",
    "\n",
    "    resized_images_TRL = resize_tensor_images(images)\n",
    "\n",
    "    # Normalize each image in the batch\n",
    "    normalized_images_TRL = torch.stack([normalize_individual_image(img) for img in resized_images_TRL])\n",
    "    normalized_batches_TRL.append((normalized_images_TRL, labels))\n",
    "\n",
    "for batch in valid_loader:\n",
    "    images, labels = batch\n",
    "\n",
    "    resized_images_VAL = resize_tensor_images(images)\n",
    "\n",
    "    # Normalize each image in the batch\n",
    "    normalized_images_VAL = torch.stack([normalize_individual_image(img) for img in resized_images_VAL])\n",
    "    normalized_batches_VAL.append((normalized_images_VAL, labels))\n",
    "\n",
    "normalized_alldata_batches_TRL = []\n",
    "normalized_alldata_batches_VAL = []\n",
    "normalized_alldata_batches_test = []\n",
    "mean, std = compute_mean_std(train_loader)\n",
    "for batch in train_loader:\n",
    "    images, labels = batch\n",
    "\n",
    "    resized_images_TRL = resize_tensor_images(images)\n",
    "    # Normalize the batch of images\n",
    "    normalized_alldata_images_TRL = normalize_images(resized_images_TRL, mean, std)\n",
    "\n",
    "    # Append the normalized images and their corresponding labels to the list\n",
    "    normalized_alldata_batches_TRL.append((normalized_alldata_images_TRL, labels))\n",
    "\n",
    "mean, std = compute_mean_std(valid_loader)\n",
    "for batch in valid_loader:\n",
    "    images, labels = batch\n",
    "\n",
    "    resized_images_VAL = resize_tensor_images(images)\n",
    "    # Normalize the batch of images\n",
    "    normalized_alldata_images_VAL = normalize_images(resized_images_VAL, mean, std)\n",
    "\n",
    "    # Append the normalized images and their corresponding labels to the list\n",
    "    normalized_alldata_batches_VAL.append((normalized_alldata_images_VAL, labels))\n",
    "\n",
    "mean, std = compute_mean_std(test_loader)\n",
    "for batch in test_loader:\n",
    "    images, labels = batch\n",
    "\n",
    "    resized_images_test = resize_tensor_images(images)\n",
    "    # Normalize the batch of images\n",
    "    normalized_alldata_images_test = normalize_images(resized_images_test, mean, std)\n",
    "\n",
    "    # Append the normalized images and their corresponding labels to the list\n",
    "    normalized_alldata_batches_test.append((normalized_alldata_images_test, labels))\n",
    "\n",
    "non_normalized_batches_TRL = []\n",
    "non_normalized_batches_VAL = []\n",
    "\n",
    "for batch in train_loader:\n",
    "    images, labels = batch\n",
    "\n",
    "    resized_images_TRL = resize_tensor_images(images)\n",
    "    non_normalized_TRL = resize_tensor_images(images) / 255\n",
    "    non_normalized_batches_TRL.append((non_normalized_TRL, labels))\n",
    "\n",
    "for batch in valid_loader:\n",
    "    images, labels = batch\n",
    "\n",
    "    resized_images_VAL = resize_tensor_images(images)\n",
    "    non_normalized_VAL = resize_tensor_images(images) / 255\n",
    "    non_normalized_batches_VAL.append((non_normalized_VAL, labels))\n",
    "\n",
    "\n",
    "# first_image_tensor = normalized_alldata_images_TRL[0]\n",
    "\n",
    "# # Convert the tensor to a NumPy array\n",
    "# first_image_numpy = tensor_to_numpy(first_image_tensor)\n",
    "\n",
    "# plt.imshow(first_image_numpy)\n",
    "# plt.axis('off')  # Remove axis markers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e97c1aba-ab0e-4d27-b704-6b72c3cca542",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2)  # New convolutional layer\n",
    "        self.fc1 = nn.Linear(32 * 32 * 32, 160)  # Adjusted for the new layer\n",
    "        self.fc2 = nn.Linear(160, 100)\n",
    "        self.fc3 = nn.Linear(100, 50)\n",
    "        self.fc4 = nn.Linear(50, 3)  # New fully connected layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # Apply the new layer\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)  # Apply the new fully connected layer\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "27ca6e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9ac2a8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 0, 1, 0, 1, 0, 2, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1])\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 2, 2, 2, 0, 0, 0, 2, 2, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 2, 2])\n",
      "tensor([0, 0, 2, 0, 2, 0, 2, 2, 2, 1, 0, 1, 0, 2, 0, 1, 0, 2, 0, 1, 1, 0, 2, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 0])\n",
      "tensor([2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1, 0, 1, 2,\n",
      "        1, 2, 0, 1, 0, 1, 0, 1])\n",
      "tensor([1, 2, 0, 1, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 1, 2, 2, 2, 0, 0,\n",
      "        0, 0, 1, 0, 2, 0, 2, 2])\n",
      "tensor([1, 1, 1, 2, 0, 1, 2, 2, 0, 1, 0, 0, 2, 2, 0, 1, 0, 0, 1, 1, 2, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1])\n",
      "tensor([1, 0, 0, 2, 0, 2, 2, 1, 0, 2, 1, 2, 2, 0, 0, 2, 1, 1, 1, 0])\n",
      "tensor([0, 0, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 0, 1, 0, 1, 0, 2, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1])\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 2, 2, 2, 0, 0, 0, 2, 2, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 2, 2])\n",
      "tensor([0, 0, 2, 0, 2, 0, 2, 2, 2, 1, 0, 1, 0, 2, 0, 1, 0, 2, 0, 1, 1, 0, 2, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 0])\n",
      "tensor([2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1, 0, 1, 2,\n",
      "        1, 2, 0, 1, 0, 1, 0, 1])\n",
      "tensor([1, 2, 0, 1, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 1, 2, 2, 2, 0, 0,\n",
      "        0, 0, 1, 0, 2, 0, 2, 2])\n",
      "tensor([1, 1, 1, 2, 0, 1, 2, 2, 0, 1, 0, 0, 2, 2, 0, 1, 0, 0, 1, 1, 2, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1])\n",
      "tensor([1, 0, 0, 2, 0, 2, 2, 1, 0, 2, 1, 2, 2, 0, 0, 2, 1, 1, 1, 0])\n",
      "tensor([0, 0, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 0, 1, 0, 1, 0, 2, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1])\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 2, 2, 2, 0, 0, 0, 2, 2, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 2, 2])\n",
      "tensor([0, 0, 2, 0, 2, 0, 2, 2, 2, 1, 0, 1, 0, 2, 0, 1, 0, 2, 0, 1, 1, 0, 2, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 0])\n",
      "tensor([2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1, 0, 1, 2,\n",
      "        1, 2, 0, 1, 0, 1, 0, 1])\n",
      "tensor([1, 2, 0, 1, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 1, 2, 2, 2, 0, 0,\n",
      "        0, 0, 1, 0, 2, 0, 2, 2])\n",
      "tensor([1, 1, 1, 2, 0, 1, 2, 2, 0, 1, 0, 0, 2, 2, 0, 1, 0, 0, 1, 1, 2, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1])\n",
      "tensor([1, 0, 0, 2, 0, 2, 2, 1, 0, 2, 1, 2, 2, 0, 0, 2, 1, 1, 1, 0])\n",
      "tensor([0, 0, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 0, 1, 0, 1, 0, 2, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1])\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 2, 2, 2, 0, 0, 0, 2, 2, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 2, 2])\n",
      "tensor([0, 0, 2, 0, 2, 0, 2, 2, 2, 1, 0, 1, 0, 2, 0, 1, 0, 2, 0, 1, 1, 0, 2, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 0])\n",
      "tensor([2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1, 0, 1, 2,\n",
      "        1, 2, 0, 1, 0, 1, 0, 1])\n",
      "tensor([1, 2, 0, 1, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 1, 2, 2, 2, 0, 0,\n",
      "        0, 0, 1, 0, 2, 0, 2, 2])\n",
      "tensor([1, 1, 1, 2, 0, 1, 2, 2, 0, 1, 0, 0, 2, 2, 0, 1, 0, 0, 1, 1, 2, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1])\n",
      "tensor([1, 0, 0, 2, 0, 2, 2, 1, 0, 2, 1, 2, 2, 0, 0, 2, 1, 1, 1, 0])\n",
      "tensor([0, 0, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 0, 1, 0, 1, 0, 2, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1])\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 2, 2, 2, 0, 0, 0, 2, 2, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 2, 2])\n",
      "tensor([0, 0, 2, 0, 2, 0, 2, 2, 2, 1, 0, 1, 0, 2, 0, 1, 0, 2, 0, 1, 1, 0, 2, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 0])\n",
      "tensor([2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1, 0, 1, 2,\n",
      "        1, 2, 0, 1, 0, 1, 0, 1])\n",
      "tensor([1, 2, 0, 1, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 1, 2, 2, 2, 0, 0,\n",
      "        0, 0, 1, 0, 2, 0, 2, 2])\n",
      "tensor([1, 1, 1, 2, 0, 1, 2, 2, 0, 1, 0, 0, 2, 2, 0, 1, 0, 0, 1, 1, 2, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1])\n",
      "tensor([1, 0, 0, 2, 0, 2, 2, 1, 0, 2, 1, 2, 2, 0, 0, 2, 1, 1, 1, 0])\n",
      "tensor([0, 0, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 0, 1, 0, 1, 0, 2, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1])\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 2, 2, 2, 0, 0, 0, 2, 2, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 2, 2])\n",
      "tensor([0, 0, 2, 0, 2, 0, 2, 2, 2, 1, 0, 1, 0, 2, 0, 1, 0, 2, 0, 1, 1, 0, 2, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 0])\n",
      "tensor([2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1, 0, 1, 2,\n",
      "        1, 2, 0, 1, 0, 1, 0, 1])\n",
      "tensor([1, 2, 0, 1, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 1, 2, 2, 2, 0, 0,\n",
      "        0, 0, 1, 0, 2, 0, 2, 2])\n",
      "tensor([1, 1, 1, 2, 0, 1, 2, 2, 0, 1, 0, 0, 2, 2, 0, 1, 0, 0, 1, 1, 2, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1])\n",
      "tensor([1, 0, 0, 2, 0, 2, 2, 1, 0, 2, 1, 2, 2, 0, 0, 2, 1, 1, 1, 0])\n",
      "tensor([0, 0, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 0, 1, 0, 1, 0, 2, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1])\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 2, 2, 2, 0, 0, 0, 2, 2, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 2, 2])\n",
      "tensor([0, 0, 2, 0, 2, 0, 2, 2, 2, 1, 0, 1, 0, 2, 0, 1, 0, 2, 0, 1, 1, 0, 2, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 0])\n",
      "tensor([2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1, 0, 1, 2,\n",
      "        1, 2, 0, 1, 0, 1, 0, 1])\n",
      "tensor([1, 2, 0, 1, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 1, 2, 2, 2, 0, 0,\n",
      "        0, 0, 1, 0, 2, 0, 2, 2])\n",
      "tensor([1, 1, 1, 2, 0, 1, 2, 2, 0, 1, 0, 0, 2, 2, 0, 1, 0, 0, 1, 1, 2, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1])\n",
      "tensor([1, 0, 0, 2, 0, 2, 2, 1, 0, 2, 1, 2, 2, 0, 0, 2, 1, 1, 1, 0])\n",
      "tensor([0, 0, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 0, 1, 0, 1, 0, 2, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1])\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 2, 2, 2, 0, 0, 0, 2, 2, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 2, 2])\n",
      "tensor([0, 0, 2, 0, 2, 0, 2, 2, 2, 1, 0, 1, 0, 2, 0, 1, 0, 2, 0, 1, 1, 0, 2, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 0])\n",
      "tensor([2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1, 0, 1, 2,\n",
      "        1, 2, 0, 1, 0, 1, 0, 1])\n",
      "tensor([1, 2, 0, 1, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 1, 2, 2, 2, 0, 0,\n",
      "        0, 0, 1, 0, 2, 0, 2, 2])\n",
      "tensor([1, 1, 1, 2, 0, 1, 2, 2, 0, 1, 0, 0, 2, 2, 0, 1, 0, 0, 1, 1, 2, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1])\n",
      "tensor([1, 0, 0, 2, 0, 2, 2, 1, 0, 2, 1, 2, 2, 0, 0, 2, 1, 1, 1, 0])\n",
      "tensor([0, 0, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 0, 1, 0, 1, 0, 2, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(normalized_alldata_batches_TRL, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # print(inputs)\n",
    "        print(labels)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c5c5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './test1.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377ccc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(normalized_alldata_batches_VAL)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "dataiter_train = iter(normalized_alldata_batches_TRL)\n",
    "images_train, labels_train = next(dataiter_train)\n",
    "\n",
    "dataiter_test = iter(normalized_alldata_batches_test)\n",
    "images_test, labels_test = next(dataiter_test)\n",
    "# print images\n",
    "# for i in range(len(images)):\n",
    "#     first_image_tensor = images[i]\n",
    "\n",
    "#     # Convert the tensor to a NumPy array\n",
    "#     first_image_numpy = tensor_to_numpy(first_image_tensor)\n",
    "\n",
    "#     # Display the image\n",
    "#     plt.imshow(first_image_numpy)\n",
    "#     plt.axis('off')  # Remove axis markers\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a17acd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0958f50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1be36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  6.3717,  -4.3532,  -0.8758],\n",
      "        [ -4.8686,   7.6854,  -6.5024],\n",
      "        [  2.3771,  -1.7594,  -1.1256],\n",
      "        [  2.3855,  -1.2246,  -0.8786],\n",
      "        [  2.4407,  -0.9329,  -1.5980],\n",
      "        [  0.5432,   0.5281,  -1.0848],\n",
      "        [ -9.4273,  10.4462,  -5.2313],\n",
      "        [ -7.5458,   7.4785,  -6.0561],\n",
      "        [  1.0999,  -7.3880,   6.1811],\n",
      "        [ -0.2073,   4.2922,  -4.3811],\n",
      "        [ -1.8541,   2.7516,  -3.1666],\n",
      "        [ -7.0683,   7.2468,  -3.7786],\n",
      "        [  1.7555,  -0.9721,  -0.2960],\n",
      "        [  3.0394,  -4.7818,   1.8282],\n",
      "        [  1.9154,  -0.8557,  -0.9290],\n",
      "        [  7.0310,  -7.2639,   0.7705],\n",
      "        [ -1.6838,   7.1378,  -6.0082],\n",
      "        [  0.6975,  -1.4552,   0.9193],\n",
      "        [  6.6812,  -2.4990,  -4.3222],\n",
      "        [  2.3911,  -1.4056,  -0.7675],\n",
      "        [  1.7738,  -0.7072,  -0.8411],\n",
      "        [  4.1534,  -1.7177,  -1.9793],\n",
      "        [  1.9767,  -1.4979,  -0.1531],\n",
      "        [ -5.8494,   5.2779,  -0.7431],\n",
      "        [  2.2142,  -1.0921,  -1.0410],\n",
      "        [  1.2990,  -1.4152,   0.2116],\n",
      "        [  6.2058,  -4.1603,  -1.6800],\n",
      "        [  5.0854,  -3.5427,  -0.2787],\n",
      "        [ -8.2887,   9.6301,  -5.4583],\n",
      "        [  3.8091,  -6.3870,   1.9548],\n",
      "        [  6.3894,  -7.5147,   1.3134],\n",
      "        [  2.6373,  -1.0317,  -1.6635],\n",
      "        [  1.1977,  -1.7702,   0.8822],\n",
      "        [  1.2575,   2.1329,  -3.8906],\n",
      "        [ -5.0587,   8.0075,  -6.2941],\n",
      "        [  2.4000,  -1.8361,  -0.2030],\n",
      "        [  2.6117,  -1.2804,  -1.3190],\n",
      "        [  3.6020,  -2.5923,  -0.4792],\n",
      "        [  2.6655,  -0.9799,  -1.6687],\n",
      "        [  1.5837,  -0.7999,  -0.5416],\n",
      "        [  3.3528,  -1.5740,  -1.2018],\n",
      "        [  2.6226,  -2.7371,   0.0757],\n",
      "        [ -4.7371,   4.9395,  -3.2858],\n",
      "        [  0.7281,  -1.4801,   0.4450],\n",
      "        [ -7.7730,  11.7396,  -8.0485],\n",
      "        [-14.3170,  16.9156,  -7.7063]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "outputs = net(images)\n",
    "outputs_train = net(images_train)\n",
    "outputs_test = net(images_test)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0fc9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  cloud edge  cloud cloud cloud cloud edge  edge  good  edge  edge  edge  cloud cloud cloud cloud edge  good  cloud cloud cloud cloud cloud edge  cloud cloud cloud cloud edge  cloud cloud cloud\n",
      "Validation Accuracy: 80.43%\n",
      "Train accuracy: 84.38%\n",
      "Test accuracy: 56.25%\n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(32)))\n",
    "# Assume 'outputs' are the logits from your network and 'labels' are your ground truth labels\n",
    "\n",
    "# Convert outputs to predicted class labels\n",
    "_, predicted_train = torch.max(outputs_train, 1)\n",
    "_, predicted_test = torch.max(outputs_test, 1)\n",
    "\n",
    "# Calculate the number of correctly predicted labels\n",
    "correct_predictions = (predicted == labels).sum().item()\n",
    "correct_predictions_train = (predicted_train == labels_train).sum().item()\n",
    "correct_predictions_test = (predicted_test == labels_test).sum().item()\n",
    "# Calculate the total number of labels\n",
    "total_labels = labels.size(0)\n",
    "total_labels_train = labels_train.size(0)\n",
    "total_labels_test = labels_test.size(0)\n",
    "# Calculate the accuracy as a percentage\n",
    "accuracy = 100 * correct_predictions / total_labels\n",
    "accuracy_train = 100 * correct_predictions_train / total_labels_train\n",
    "accuracy_test = 100 * correct_predictions_test / total_labels_test\n",
    "print('Validation Accuracy: {:.2f}%'.format(accuracy))\n",
    "print('Train accuracy: {:.2f}%'.format(accuracy_train))\n",
    "print('Test accuracy: {:.2f}%'.format(accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0556690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
