{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: 1\n",
      "GPU 0: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # GPU index\n",
    "\n",
    "print(\"Available GPUs:\", torch.cuda.device_count())\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import sys\n",
    "sys.path.insert(1, os.path.join(\"..\", \"data\"))\n",
    "sys.path.insert(1, os.path.join(\"..\", \"utils\"))\n",
    "from data_utils import Dataset\n",
    "from plot_utils import plot_image\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the data folder (update the variable to your path).\n",
    "path_data=os.path.join(\"..\", \"data\")\n",
    "# Seed value\n",
    "seed=1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing class: Cloud: 143it [00:07, 19.15it/s]\n",
      "Parsing class: Edge: 97it [00:04, 22.70it/s]\n",
      "Parsing class: Good: 64it [00:03, 18.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cloud</th>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edge</th>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train  valid  test\n",
       "cloud    100     24    19\n",
       "edge      64     15    18\n",
       "good      48      7     9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=Dataset(path_data=path_data, seed=seed)\n",
    "dataset.read_data()\n",
    "dataset.get_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "# Train loader\n",
    "train_loader = DataLoader(dataset.get_split(\"train\"), batch_size=batch_size, pin_memory=False, shuffle=True)\n",
    "# Cross validation data loader\n",
    "valid_loader = DataLoader(dataset.get_split(\"valid\"), batch_size=batch_size, pin_memory=False, shuffle=True)\n",
    "# Test data loader\n",
    "test_loader = DataLoader(dataset.get_split(\"test\"), batch_size=batch_size, pin_memory=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('cloud', 'edge', 'good')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start of training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def resize_tensor_images(images, size=(256, 256)):\n",
    "    # Resize the batch of images\n",
    "    return F.interpolate(images, size=size, mode='bilinear', align_corners=False)\n",
    "\n",
    "def compute_mean_std(loader):\n",
    "    # Computation of mean and standard deviation of batches\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_images_count = 0\n",
    "\n",
    "    for images, _ in loader:\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "        total_images_count += batch_samples\n",
    "\n",
    "    mean /= total_images_count\n",
    "    std /= total_images_count\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "def normalize_images(images, mean, std):\n",
    "    # Normalizing images with previously computed mean and standard deviation\n",
    "    normalized_images = (images - mean.view(-1, 1, 1)) / std.view(-1, 1, 1)\n",
    "    return normalized_images\n",
    "    \n",
    "def tensor_to_numpy(tensor):\n",
    "    # Rescale the tensor to 0-1 range\n",
    "    tensor = tensor - tensor.min()\n",
    "    tensor = tensor / tensor.max()\n",
    "    # Move the tensor to CPU if it's on GPU\n",
    "    tensor = tensor.cpu()\n",
    "    # Convert to numpy and transpose from CxHxW to HxWxC for visualization\n",
    "    numpy_image = tensor.numpy()\n",
    "    numpy_image = np.transpose(numpy_image, (1, 2, 0))\n",
    "\n",
    "    return numpy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = compute_mean_std(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(data_loader, mean, std):\n",
    "    UNPRO_batches = []\n",
    "    batches = []\n",
    "    \n",
    "    for batch in data_loader:\n",
    "        images, labels = batch\n",
    "        resized_images = resize_tensor_images(images)\n",
    "        UNPRO_batches.append((resized_images, labels))\n",
    "        normalized_alldata_images = normalize_images(resized_images, mean, std)\n",
    "\n",
    "        # Append the normalized images and their corresponding labels to the list\n",
    "        batches.append((normalized_alldata_images, labels))\n",
    "    return UNPRO_batches, batches\n",
    "\n",
    "UNPRO_batches_TRL, batches_TRL = normalization(train_loader, mean, std)\n",
    "UNPRO_batches_VAL, batches_VAL = normalization(valid_loader, mean, std)\n",
    "UNPRO_batches_TST, batches_TST = normalization(test_loader, mean, std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 25, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(25),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(25, 25, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv_layer_2 = nn.Sequential(\n",
    "            nn.Conv2d(25, 25, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(25, 25, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=409600,\n",
    "                      out_features=3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv_layer_1(x)\n",
    "        x = self.conv_layer_2(x)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.00001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "accuracy_fn = Accuracy(task=\"multiclass\", num_classes=3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               batches,\n",
    "               loss_fn,\n",
    "               optimizer,\n",
    "               accuracy,\n",
    "               device: torch.device = device):\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    for batch, (images, labels) in enumerate(batches, 0):\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        y_logits = model(images)\n",
    "\n",
    "        # Calculate loss on 1 batch of data\n",
    "        loss = loss_fn(y_logits, labels)\n",
    "        acc = accuracy(y_logits.argmax(dim=-1), labels)\n",
    "        train_loss += loss\n",
    "        train_acc += acc\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_acc = train_acc / len(batches)\n",
    "    train_loss = train_loss / len(batches)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Training Accuracy: {train_acc*100:.3f}\")\n",
    "    return train_acc, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_step(model,\n",
    "              batches,\n",
    "              loss_fn,\n",
    "              accuracy,\n",
    "              device: torch.device = device):\n",
    "    validation_loss, validation_acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for images_validation, labels_validation in batches:\n",
    "            images_validation, labels_validation = images_validation.to(device), labels_validation.to(device)\n",
    "            \n",
    "            validation_logits = model(images_validation)\n",
    "            validation_loss += loss_fn(validation_logits, labels_validation)\n",
    "            validation_acc += accuracy(validation_logits.argmax(dim=-1), labels_validation)\n",
    "\n",
    "        validation_loss /= len(batches)\n",
    "        validation_acc /= len(batches)\n",
    "    print(f\"Validation Loss: {validation_loss:.4f}, Validation Accuracy: {validation_acc*100:.4f}%\")\n",
    "    return validation_acc, validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model,\n",
    "              batches,\n",
    "              loss_fn,\n",
    "              accuracy,\n",
    "              device: torch.device = device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for images_test, labels_test in batches:\n",
    "            images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "            \n",
    "            test_logits = model(images_test)\n",
    "            test_loss += loss_fn(test_logits, labels_test)\n",
    "            test_acc += accuracy(test_logits.argmax(dim=-1), labels_test)\n",
    "\n",
    "        test_loss /= len(batches)\n",
    "        test_acc /= len(batches)\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc*100:.4f}%\")\n",
    "    return test_acc, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbdd76a4c63949cd998118b59b6f2171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 85.000, Train Loss: 0.413\n",
      "Validation Loss: 0.6306, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6927, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 85.000, Train Loss: 0.412\n",
      "Validation Loss: 0.6307, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6927, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 85.000, Train Loss: 0.412\n",
      "Validation Loss: 0.6308, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6926, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 85.000, Train Loss: 0.411\n",
      "Validation Loss: 0.6309, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6925, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 85.000, Train Loss: 0.410\n",
      "Validation Loss: 0.6310, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6925, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 85.000, Train Loss: 0.409\n",
      "Validation Loss: 0.6311, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6924, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 85.446, Train Loss: 0.408\n",
      "Validation Loss: 0.6313, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6923, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 85.446, Train Loss: 0.408\n",
      "Validation Loss: 0.6314, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6923, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 85.893, Train Loss: 0.407\n",
      "Validation Loss: 0.6315, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6922, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 85.893, Train Loss: 0.406\n",
      "Validation Loss: 0.6317, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6921, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 85.893, Train Loss: 0.405\n",
      "Validation Loss: 0.6318, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6921, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 85.893, Train Loss: 0.405\n",
      "Validation Loss: 0.6319, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6920, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 85.893, Train Loss: 0.404\n",
      "Validation Loss: 0.6321, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6920, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 85.893, Train Loss: 0.403\n",
      "Validation Loss: 0.6322, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6919, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 85.893, Train Loss: 0.402\n",
      "Validation Loss: 0.6324, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6919, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 85.893, Train Loss: 0.402\n",
      "Validation Loss: 0.6325, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6919, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 85.893, Train Loss: 0.401\n",
      "Validation Loss: 0.6327, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6918, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 85.893, Train Loss: 0.400\n",
      "Validation Loss: 0.6328, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6918, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 85.893, Train Loss: 0.399\n",
      "Validation Loss: 0.6330, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6917, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 85.893, Train Loss: 0.399\n",
      "Validation Loss: 0.6332, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6917, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 86.339, Train Loss: 0.398\n",
      "Validation Loss: 0.6333, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6917, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 86.339, Train Loss: 0.397\n",
      "Validation Loss: 0.6335, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6917, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 86.339, Train Loss: 0.396\n",
      "Validation Loss: 0.6337, Validation Accuracy: 72.7679%\n",
      "Test Loss: 0.6916, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 86.339, Train Loss: 0.396\n",
      "Validation Loss: 0.6338, Validation Accuracy: 71.2054%\n",
      "Test Loss: 0.6916, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 86.339, Train Loss: 0.395\n",
      "Validation Loss: 0.6340, Validation Accuracy: 71.2054%\n",
      "Test Loss: 0.6916, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 86.339, Train Loss: 0.394\n",
      "Validation Loss: 0.6342, Validation Accuracy: 69.6429%\n",
      "Test Loss: 0.6916, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 86.339, Train Loss: 0.393\n",
      "Validation Loss: 0.6344, Validation Accuracy: 69.6429%\n",
      "Test Loss: 0.6916, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 86.339, Train Loss: 0.393\n",
      "Validation Loss: 0.6346, Validation Accuracy: 69.6429%\n",
      "Test Loss: 0.6916, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 86.339, Train Loss: 0.392\n",
      "Validation Loss: 0.6347, Validation Accuracy: 69.6429%\n",
      "Test Loss: 0.6915, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 86.339, Train Loss: 0.391\n",
      "Validation Loss: 0.6349, Validation Accuracy: 69.6429%\n",
      "Test Loss: 0.6915, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 86.339, Train Loss: 0.390\n",
      "Validation Loss: 0.6351, Validation Accuracy: 69.6429%\n",
      "Test Loss: 0.6915, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 86.339, Train Loss: 0.390\n",
      "Validation Loss: 0.6353, Validation Accuracy: 69.6429%\n",
      "Test Loss: 0.6915, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 86.339, Train Loss: 0.389\n",
      "Validation Loss: 0.6355, Validation Accuracy: 69.6429%\n",
      "Test Loss: 0.6915, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 86.339, Train Loss: 0.388\n",
      "Validation Loss: 0.6357, Validation Accuracy: 69.6429%\n",
      "Test Loss: 0.6915, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 86.339, Train Loss: 0.388\n",
      "Validation Loss: 0.6359, Validation Accuracy: 69.6429%\n",
      "Test Loss: 0.6915, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 86.339, Train Loss: 0.387\n",
      "Validation Loss: 0.6361, Validation Accuracy: 69.6429%\n",
      "Test Loss: 0.6915, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 86.339, Train Loss: 0.386\n",
      "Validation Loss: 0.6364, Validation Accuracy: 69.6429%\n",
      "Test Loss: 0.6915, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 86.339, Train Loss: 0.385\n",
      "Validation Loss: 0.6366, Validation Accuracy: 69.6429%\n",
      "Test Loss: 0.6915, Test Accuracy: 63.6161%\n",
      "Training Accuracy: 86.339, Train Loss: 0.385\n",
      "Validation Loss: 0.6368, Validation Accuracy: 69.6429%\n",
      "Test Loss: 0.6915, Test Accuracy: 63.6161%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m               \u001b[49m\u001b[43mbatches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatches_TRL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m               \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m               \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m               \u001b[49m\u001b[43maccuracy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccuracy_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m               \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m               \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     validation_step(model\u001b[38;5;241m=\u001b[39mnet,\n\u001b[0;32m     13\u001b[0m               batches\u001b[38;5;241m=\u001b[39mbatches_VAL,\n\u001b[0;32m     14\u001b[0m               loss_fn\u001b[38;5;241m=\u001b[39mloss_fn,\n\u001b[0;32m     15\u001b[0m               accuracy\u001b[38;5;241m=\u001b[39maccuracy_fn,\n\u001b[0;32m     16\u001b[0m               device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     17\u001b[0m     test_step(model\u001b[38;5;241m=\u001b[39mnet,\n\u001b[0;32m     18\u001b[0m               batches\u001b[38;5;241m=\u001b[39mbatches_TST,\n\u001b[0;32m     19\u001b[0m               loss_fn\u001b[38;5;241m=\u001b[39mloss_fn,\n\u001b[0;32m     20\u001b[0m               accuracy\u001b[38;5;241m=\u001b[39maccuracy_fn,\n\u001b[0;32m     21\u001b[0m               device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "Cell \u001b[1;32mIn[33], line 18\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(model, batches, loss_fn, optimizer, accuracy, device)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Calculate loss on 1 batch of data\u001b[39;00m\n\u001b[0;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_logits, labels)\n\u001b[1;32m---> 18\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_logits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m     20\u001b[0m train_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m acc\n",
      "File \u001b[1;32mc:\\Users\\ianma\\anaconda3\\envs\\OMICRON\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ianma\\anaconda3\\envs\\OMICRON\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ianma\\anaconda3\\envs\\OMICRON\\Lib\\site-packages\\torchmetrics\\metric.py:298\u001b[0m, in \u001b[0;36mMetric.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_full_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_reduce_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache\n",
      "File \u001b[1;32mc:\\Users\\ianma\\anaconda3\\envs\\OMICRON\\Lib\\site-packages\\torchmetrics\\metric.py:367\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# allow grads for batch computation\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[1;32m--> 367\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m batch_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ianma\\anaconda3\\envs\\OMICRON\\Lib\\site-packages\\torchmetrics\\metric.py:457\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 457\u001b[0m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[1;32mc:\\Users\\ianma\\anaconda3\\envs\\OMICRON\\Lib\\site-packages\\torchmetrics\\classification\\stat_scores.py:322\u001b[0m, in \u001b[0;36mMulticlassStatScores.update\u001b[1;34m(self, preds, target)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update state with predictions and targets.\"\"\"\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_args:\n\u001b[1;32m--> 322\u001b[0m     \u001b[43m_multiclass_stat_scores_tensor_validation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultidim_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m preds, target \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_format(preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k)\n\u001b[0;32m    326\u001b[0m tp, fp, tn, fn \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_update(\n\u001b[0;32m    327\u001b[0m     preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultidim_average, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index\n\u001b[0;32m    328\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ianma\\anaconda3\\envs\\OMICRON\\Lib\\site-packages\\torchmetrics\\functional\\classification\\stat_scores.py:307\u001b[0m, in \u001b[0;36m_multiclass_stat_scores_tensor_validation\u001b[1;34m(preds, target, num_classes, multidim_average, ignore_index)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEither `preds` and `target` both should have the (same) shape (N, ...), or `target` should be (N, ...)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and `preds` should be (N, C, ...).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    305\u001b[0m     )\n\u001b[1;32m--> 307\u001b[0m num_unique_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    308\u001b[0m check \u001b[38;5;241m=\u001b[39m num_unique_values \u001b[38;5;241m>\u001b[39m num_classes \u001b[38;5;28;01mif\u001b[39;00m ignore_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m num_unique_values \u001b[38;5;241m>\u001b[39m num_classes \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check:\n",
      "File \u001b[1;32mc:\\Users\\ianma\\anaconda3\\envs\\OMICRON\\Lib\\site-packages\\torch\\_jit_internal.py:488\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ianma\\anaconda3\\envs\\OMICRON\\Lib\\site-packages\\torch\\_jit_internal.py:488\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ianma\\anaconda3\\envs\\OMICRON\\Lib\\site-packages\\torch\\functional.py:976\u001b[0m, in \u001b[0;36m_return_output\u001b[1;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unique_impl(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28msorted\u001b[39m, return_inverse, return_counts, dim)\n\u001b[1;32m--> 976\u001b[0m output, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_unique_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\ianma\\anaconda3\\envs\\OMICRON\\Lib\\site-packages\\torch\\functional.py:890\u001b[0m, in \u001b[0;36m_unique_impl\u001b[1;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[0;32m    882\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39munique_dim(\n\u001b[0;32m    883\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    884\u001b[0m         dim,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    887\u001b[0m         return_counts\u001b[38;5;241m=\u001b[39mreturn_counts,\n\u001b[0;32m    888\u001b[0m     )\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 890\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unique2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, inverse_indices, counts\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "epochs = 100\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_step(model=net,\n",
    "               batches=batches_TRL,\n",
    "               loss_fn=loss_fn,\n",
    "               optimizer=optimizer,\n",
    "               accuracy=accuracy_fn,\n",
    "               device=device\n",
    "               )\n",
    "    validation_step(model=net,\n",
    "              batches=batches_VAL,\n",
    "              loss_fn=loss_fn,\n",
    "              accuracy=accuracy_fn,\n",
    "              device=device)\n",
    "    test_step(model=net,\n",
    "              batches=batches_TST,\n",
    "              loss_fn=loss_fn,\n",
    "              accuracy=accuracy_fn,\n",
    "              device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OMICRON",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
